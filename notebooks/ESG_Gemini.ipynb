{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab03f5fe",
   "metadata": {},
   "source": [
    "# ESG Metric Extraction\n",
    "\n",
    "## Structure\n",
    "\n",
    "### Example: AAPL\n",
    "1. Imports\n",
    "2. Data Extraction\n",
    "3. Prompt Definition\n",
    "4. Response Retrieval\n",
    "\n",
    "### Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132f862",
   "metadata": {},
   "source": [
    "## Example: AAPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c232e",
   "metadata": {},
   "source": [
    "### 1. Imports:\n",
    "\n",
    "_from google import genai_:    \n",
    "For this we are going to use Google's Gemini as our LLM for the heavy lifting.    \n",
    "\n",
    "_from langchain.prompts import PromptTemplate_:   \n",
    "We once again use langchain and its prompt template to make an instruction set for the LLM \n",
    "\n",
    "_import fitz_:    \n",
    "For the document instruction we use the PyMuPDF also know as fitz. It will do most of the preprocessing from pdf loading to text extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89a2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from google import genai\n",
    "from langchain.prompts import PromptTemplate\n",
    "import fitz  # PyMuPDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32639bf",
   "metadata": {},
   "source": [
    "#### File path:\n",
    "Currently in this repository it is find in _data/raw/ESG_ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455ea85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_name = 'AAPL'\n",
    "file_path = f'../data/raw/ESG/{ticker_name}.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4231f0",
   "metadata": {},
   "source": [
    "### 2. Data Extraction\n",
    "\n",
    "This function extracts the text from the pdf file. It filters the document for header and footers to not use any uncessary tokens on the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5c32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(doc_path, margin_height=50):\n",
    "    doc = fitz.open(doc_path)\n",
    "    all_text = []\n",
    "\n",
    "    for page in doc:\n",
    "        page_height = page.rect.height\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in blocks:\n",
    "            if \"lines\" not in block:\n",
    "                continue\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    text = span[\"text\"].strip()\n",
    "                    y0, y1 = span[\"bbox\"][1], span[\"bbox\"][3]\n",
    "\n",
    "                    # Skip if within header/footer margin\n",
    "                    if y1 < margin_height or y0 > (page_height - margin_height):\n",
    "                        continue\n",
    "\n",
    "                    all_text.append(text)\n",
    "\n",
    "    return \"\\n\".join(all_text)\n",
    "\n",
    "pdf_text = extract_pdf_text(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115900e9",
   "metadata": {},
   "source": [
    "### 3. Prompt Definition.\n",
    "With larger Models like Gemini and ChatGPT, the prompt has a siginificant impact on the output. \n",
    "These prompts are highly configurable and designable to your goals.\n",
    "\n",
    "In this case we want the model to pull all the data that may in any way be a metric related to ESG from the document.    \n",
    "To measure this we require it to return the unit in ISO format so that the different profiles comparable later on.    \n",
    "Lastly we want it to return it in JSON format so it is easily manipulatable and useful for saving and loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e092229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\{'\n",
      "/var/folders/7k/ytnljb093xg6bbfksvnhyg940000gn/T/ipykernel_22667/2530921994.py:3: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  template=\"\"\"You are an expert in environmental, social, and governance (ESG) data extraction and reporting.\n",
      "/var/folders/7k/ytnljb093xg6bbfksvnhyg940000gn/T/ipykernel_22667/2530921994.py:3: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  template=\"\"\"You are an expert in environmental, social, and governance (ESG) data extraction and reporting.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for PromptTemplate\n  Value error, unmatched '{' in format spec [type=value_error, input_value={'input_variables': ['doc...'partial_variables': {}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m prompt = \u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocument_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[33;43mYou are an expert in environmental, social, and governance (ESG) data extraction and reporting.\u001b[39;49m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[33;43m            Your task is to carefully extract **all relevant ESG metrics** from the following report text. \u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[33;43m            These include, but are not limited to: emissions (Scopes 1, 2, 3), energy usage, water usage, waste, recycled materials, carbon footprint, renewable energy deployment, and any target/goal progression. \u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[33;43m            Please include all the data from previous years as well.\u001b[39;49m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33;43m            Please:\u001b[39;49m\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[33;43m            1. Structure the output as **valid JSON**.\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[33;43m            2. Include **all available years** for each metric (not just the current year).\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[33;43m            3. Make sure to take a look at and for **tables**. Some data may be in tabular format and structured as such.\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[33;43m            4. Use **standardized ISO units** where possible (e.g., metric tons of CO2e, MWh, gallons, percentages). Convert if necessary.\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[33;43m            5. Use **clear and consistent keys**, and group metrics by category such as \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEmissions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEnergy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWater\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMaterials\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWaste\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, etc.\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[33;43m            6. Omit interpretation — just provide structured data as precisely as stated in the document.\u001b[39;49m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[33;43m            Here is the report text:\u001b[39;49m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[33;43m            --- START OF REPORT TEXT ---\u001b[39;49m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33;43m            \u001b[39;49m\u001b[38;5;132;43;01m{document_text}\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[33;43m            --- END OF REPORT TEXT ---\u001b[39;49m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;43m            Ensure the output is JSON-serializable and can be parsed using json.loads() in Python:\u001b[39;49m\n\u001b[32m     27\u001b[39m \u001b[33;43m            Please provide the output in the following format where the hierachy is \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCategory > Subcategory > Year > Metric and value\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m like the following:\u001b[39;49m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;43m             \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDesignAndMaterials\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m     30\u001b[39m \u001b[33;43m                \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRecycledGoldIncrease\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m     31\u001b[39m \u001b[33;43m                    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2021\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m{\u001b[39;49m\n\u001b[32m     32\u001b[39m \u001b[33;43m                        \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: 1,\u001b[39;49m\n\u001b[32m     33\u001b[39m \u001b[33;43m                        \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     34\u001b[39m \u001b[33;43m                    \u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m},\u001b[39;49m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[33;43m            Now return the extracted ESG metrics in valid JSON format:\u001b[39;49m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;43m            \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     39\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/FinRAG/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/FinRAG/.venv/lib/python3.12/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for PromptTemplate\n  Value error, unmatched '{' in format spec [type=value_error, input_value={'input_variables': ['doc...'partial_variables': {}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"document_text\"],\n",
    "    template=\"\"\"You are an expert in environmental, social, and governance (ESG) data extraction and reporting.\n",
    "\n",
    "            Your task is to carefully extract **all relevant ESG metrics** from the following report text. \n",
    "            These include, but are not limited to: emissions (Scopes 1, 2, 3), energy usage, water usage, waste, recycled materials, carbon footprint, renewable energy deployment, and any target/goal progression. \n",
    "            Please include all the data from previous years as well.\n",
    "\n",
    "            Please:\n",
    "\n",
    "            1. Structure the output as **valid JSON**.\n",
    "            2. Include **all available years** for each metric (not just the current year).\n",
    "            3. Make sure to take a look at and for **tables**. Some data may be in tabular format and structured as such.\n",
    "            4. Use **standardized ISO units** where possible (e.g., metric tons of CO2e, MWh, gallons, percentages). Convert if necessary.\n",
    "            5. Use **clear and consistent keys**, and group metrics by category such as \"Emissions\", \"Energy\", \"Water\", \"Materials\", \"Waste\", etc.\n",
    "            6. Omit interpretation — just provide structured data as precisely as stated in the document.\n",
    "\n",
    "            Here is the report text:\n",
    "\n",
    "            --- START OF REPORT TEXT ---\n",
    "\n",
    "            {document_text}\n",
    "\n",
    "            --- END OF REPORT TEXT ---\n",
    "\n",
    "            Ensure the output is JSON-serializable and can be parsed using json.loads() in Python:\n",
    "            Please provide the output in the following format where the hierachy is \"Category > Subcategory > Year > Metric and value\" like the following:\n",
    "\n",
    "            \"DesignAndMaterials\": [\n",
    "                \"RecycledGoldIncrease\": [\n",
    "                    \"2021\": [\n",
    "                        \"value\": 1,\n",
    "                        \"unit\": \"%\"\n",
    "                    ],\n",
    "                ]\n",
    "            ],\n",
    "\n",
    "            Now return the extracted ESG metrics in valid JSON format:\n",
    "        \n",
    "            \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3ca07",
   "metadata": {},
   "source": [
    "### 4. Response Retrieval\n",
    "\n",
    "This is the model definition as per the Google API. For this you will require an API Key that you can get [here](https://aistudio.google.com/apikey).    \n",
    "The model will output a class called _GenerateContentResponse_ that contains metadata and the actually text at output.text.\n",
    "\n",
    "Since its output is json it will output a markdown format preceded by \\`\\`\\`json and succeded by \\`\\`\\` which we filter out.\n",
    "\n",
    "The rest is then in nice json format that we use for our metric. This will be done in a different document though. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b861c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_response = client.models.generate_content(\n",
    "#     model=\"gemini-2.0-flash\",\n",
    "#     contents=prompt.format(document_text=pdf_text),\n",
    "# )\n",
    "# output_text = json_response.text.replace(\"```json\", \"\").replace(\"```\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2034bfd",
   "metadata": {},
   "source": [
    "### 5. Saving the Data\n",
    "\n",
    "After we received the output text we need to make sure we can saved it to a json file, since this is the filetype we are going to be going with.\n",
    "For this we will be using _json5_ as a tolerant json laoder and _ast_ as our string to json converter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json5\n",
    "# import json\n",
    "# import ast\n",
    "# clean_json_string = ast.literal_eval(f\"'''{output_text}'''\")\n",
    "# parsed_json = json5.loads(clean_json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a85fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"../data/processed/ESG/{ticker_name}.json\", \"w\") as json_file:\n",
    "#     json.dump(parsed_json, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3f24a",
   "metadata": {},
   "source": [
    "## Full Pipeline with Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.gemini_pipeline import GeminiPipeline\n",
    "import sys\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = GeminiPipeline(prompt_template=prompt, source_path='../data/raw/ESG', target_path='../data/processed/ESG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec788d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:10<00:00, 17.74s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8b4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
